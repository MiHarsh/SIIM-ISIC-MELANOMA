{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "gold_medal_approach.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FCwwf4k2HUJP"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanish-g/SIIM-ISIC-MELANOMA/blob/master/gold_medal_approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b-pezc3HibC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KN-jP1r-Mza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX3Cb4RZDIyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ-uIWePJhJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSmqXhm3Jpa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"odetoinfinity\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"68cff7f51defb2eee5f4ba505815416c\" # key from the json file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hNdz5AyYOCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/jpeg-melanoma-512x512/\n",
        "%cd /content/jpeg-melanoma-512x512/\n",
        "!kaggle datasets download -d cdeotte/jpeg-melanoma-512x512\n",
        "!unzip -qq /content/jpeg-melanoma-512x512/jpeg-melanoma-512x512.zip\n",
        "!rm -r /content/jpeg-melanoma-512x512/jpeg-melanoma-512x512.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5eZbOudqnbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/\n",
        "!mkdir /content/jpeg-isic2019-512x512/\n",
        "%cd /content/jpeg-isic2019-512x512/\n",
        "!kaggle datasets download -d cdeotte/jpeg-isic2019-512x512\n",
        "!unzip -qq /content/jpeg-isic2019-512x512/jpeg-isic2019-512x512.zip\n",
        "!rm -r /content/jpeg-isic2019-512x512/jpeg-isic2019-512x512.zip\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wg7RF6gaYax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "id": "R0lWwhxhHUIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install efficientnet-pytorch --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "A-7hpfJuHUIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from PIL import Image\n",
        "from torchvision import transforms as T\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import numpy as np\n",
        "from fastprogress.fastprogress import master_bar, progress_bar\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from torchvision import models\n",
        "import pdb\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import pickle "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ikJqgiHUHUId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def list_files(path:Path):\n",
        "    return [o for o in path.iterdir()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99sfe_d6cQIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df=pd.read_csv('x.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPv7u6JScYWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr2020=train_df[train_df.year==2020].reset_index(drop=True)\n",
        "tr2019=train_df[train_df.year==2018].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-1nUoLfcZ2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(tr2020.shape[0]):\n",
        "    tr2020.loc[i,'image_name']=os.path.join('/content/jpeg-melanoma-512x512/train/',tr2020.iloc[i].image_name+'.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-UDAR9Gcgrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(tr2019.shape[0]):\n",
        "    tr2019.loc[i,'image_name']=os.path.join('/content/jpeg-isic2019-512x512/train/',tr2019.iloc[i].image_name+'.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijamU7p_ckIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_concat=pd.concat([tr2020,tr2019],join='inner',axis=0).reset_index(drop=True)\n",
        "tr_concat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rli7CjzOB6zA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tr_concat.drop(columns=['Unnamed: 0'],inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AEUgt4KcnQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df=pd.read_csv('/content/jpeg-melanoma-512x512/test.csv')\n",
        "for i in range(test_df.shape[0]):\n",
        "    test_df.loc[i,'image_name']=os.path.join('/content/jpeg-melanoma-512x512/test/',test_df.iloc[i].image_name+'.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2tX1Of8HUIf",
        "colab_type": "text"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "hVCJkEvQHUIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = Path('/content/jpeg-melanoma-512x512/')\n",
        "df_path = Path('/content/jpeg-melanoma-512x512/')\n",
        "im_sz = 512\n",
        "bs = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1JhgnYP9HUIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_fnames = list_files(path/'train')\n",
        "df = pd.read_csv(df_path/'train.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0Dg3NRcHUIm",
        "colab_type": "text"
      },
      "source": [
        "The dataset contains around 35K images out of which only 584 images are malignant. That makes only 1.8% of the total dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HUTMHOF9HUIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.target.value_counts(),df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "Hs0GRBlTHUIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Samples with Melanoma\")\n",
        "imgs = df[df.target==1]['image_name'].values\n",
        "_, axs = plt.subplots(2, 5, figsize=(20, 8))\n",
        "axs = axs.flatten()\n",
        "for f_name,ax in zip(imgs[:10],axs):\n",
        "    img = Image.open(path/f'train/{f_name}.jpg')\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(\"Samples without Melanoma\")\n",
        "imgs = df[df.target==0]['image_name'].values\n",
        "_, axs = plt.subplots(2, 5, figsize=(20, 8))\n",
        "axs = axs.flatten()\n",
        "for f_name,ax in zip(imgs[:10],axs):\n",
        "    img = Image.open(path/f'train/{f_name}.jpg')\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')    \n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2csVYYaRCSQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/4uiiurz1/pytorch-auto-augment > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEQyUXucC3PQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, './pytorch-auto-augment')\n",
        "from auto_augment import AutoAugment, Cutout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZHXfyYIC8ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#AUTO AUGMENT\n",
        "def get_augmentations(p=0.5):\n",
        "    imagenet_stats = {'mean':[0.485, 0.456, 0.406], 'std':[0.229, 0.224, 0.225]}\n",
        "    train_tfms=transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        AutoAugment(),\n",
        "        Cutout(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    test_tfms=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    return train_tfms, test_tfms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_conLfsHUIs",
        "colab_type": "text"
      },
      "source": [
        "# Data Augmentation\n",
        "\n",
        "We use albumentations to perform augmentations. Since the dataset is small and we are not using any external dataset in this Kernel, an increased augmentation can be helpful. You can play with the augmentation argument to either increase or decrease the amount of data augmentation applied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GwDkT246HUIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_augmentations(p=0.5):\n",
        "    imagenet_stats = {'mean':[0.485, 0.456, 0.406], 'std':[0.229, 0.224, 0.225]}\n",
        "    train_tfms = A.Compose([\n",
        "        A.RandomSizedCrop(min_max_height=(64,384),height=384,width=384,p=0.7),\n",
        "        A.Resize(384,384,always_apply=1,p=1),\n",
        "        A.Cutout(num_holes=8,max_h_size=64,max_w_size=64,p=p),\n",
        "        A.IAAAffine(shear=2.0,rotate=180),\n",
        "        A.HueSaturationValue(hue_shift_limit=0.2,sat_shift_limit=0.1,val_shift_limit=0.1),\n",
        "        A.Flip(p=p),\n",
        "        A.RandomRotate90(p=p),\n",
        "        ToTensor(normalize=imagenet_stats)\n",
        "        ])\n",
        "    test_tfms = A.Compose([\n",
        "        ToTensor(normalize=imagenet_stats)\n",
        "        ])\n",
        "    return train_tfms, test_tfms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wW1IdlrsHUIv",
        "colab_type": "text"
      },
      "source": [
        "# Train/Validation split\n",
        "- We use a simple 80/20 split based on the triple stratified K-Fold split. \n",
        "- We remove all the duplicate images.\n",
        "- TF record - id with values 12,13,14 are put into validation split and the rest into train split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Dp32QP-rHUIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_val_split(df):\n",
        "    #Remove Duplicates\n",
        "    tr2018=df[df.year==2018].reset_index(drop=True)\n",
        "    tr2020=df[df.year==2020].reset_index(drop=True)\n",
        "    valid_df=tr2020[tr2020.kfold==4].reset_index(drop=True)\n",
        "    train=tr2020[tr2020.kfold!=4].reset_index(drop=True)\n",
        "    hold_df=tr2018[tr2018.kfold==0].reset_index(drop=True)\n",
        "    tr2018=tr2018[tr2018.kfold!=0].reset_index(drop=True)\n",
        "    train_df=pd.concat([train,tr2018],axis=0,join='inner')\n",
        "    return train_df,valid_df,hold_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-5Fi_TBHUIy",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "t0vRrQrSHUIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MelanomaDataset(Dataset):\n",
        "    def __init__(self,df,im_path,transforms=None,is_test=False):\n",
        "        self.df = df\n",
        "        self.im_path = im_path\n",
        "        self.transforms = transforms\n",
        "        self.is_test = is_test\n",
        "        \n",
        "    def __getitem__(self,idx):\n",
        "        img_path = self.df.iloc[idx]['image_name']  \n",
        "        img = Image.open(img_path)\n",
        "        if self.transforms:\n",
        "            img = self.transforms(**{\"image\": np.array(img)})[\"image\"]\n",
        "            \n",
        "        if self.is_test:\n",
        "            return img\n",
        "        target = self.df.iloc[idx]['target']\n",
        "        return img,torch.tensor([target],dtype=torch.float32)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbXYo3mHDa-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Auto Augment\n",
        "class MelanomaDataset(Dataset):\n",
        "    def __init__(self,df,im_path,transforms=None,is_test=False):\n",
        "        self.df = df\n",
        "        self.im_path = im_path\n",
        "        self.transforms = transforms\n",
        "        self.is_test = is_test\n",
        "        \n",
        "    def __getitem__(self,idx):\n",
        "        img_path = self.df.iloc[idx]['image_name']\n",
        "        img = Image.open(img_path)\n",
        "        img=img.resize((256,256))\n",
        "        if self.transforms:\n",
        "#             img = self.transforms(**{\"image\": np.array(img)})[\"image\"]\n",
        "            img=self.transforms(img)\n",
        "            \n",
        "        if self.is_test:\n",
        "            return img\n",
        "        target = self.df.iloc[idx]['target']\n",
        "        return img,torch.tensor([target],dtype=torch.float32)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2K0uuu9DldZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from albumentations.pytorch import ToTensor\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTSiH0V6X3tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tfms,test_tfms = get_augmentations(p=0.5)\n",
        "#df = pd.read_csv(df_path/'train.csv')\n",
        "train_df,valid_df = get_train_val_split(tr_concat)\n",
        "train_ds = MelanomaDataset(df=train_df,im_path=path/'train',transforms=train_tfms)\n",
        "train_dl = DataLoader(dataset=train_ds,batch_size=bs,shuffle=True,num_workers=4)\n",
        "image,labels = next(iter(train_dl))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYyfIHBcYStP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "def show_img(img):\n",
        "    plt.figure(figsize=(18,15))\n",
        "    img = img / 4+0.5 \n",
        "    npimg = img.numpy()\n",
        "    npimg = np.clip(npimg, 0., 1.)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "show_img(torchvision.utils.make_grid(image))\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "\n",
        "\n",
        "# Make a grid from batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKRlweMAHUI1",
        "colab_type": "text"
      },
      "source": [
        "# Model \n",
        "\n",
        "Efficientnets have proved themselves in the last year as a key to winning competitions. You can try different Efficientnet model by passing the right model name. Changing the number in the model name `efficientnet-b0` gives you different models. The larger the number the more complex/bigger and better the model is. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xAyuLUL_HUI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MelanomaEfficientNet(nn.Module):\n",
        "    def __init__(self,model_name='efficientnet-b3',pool_type=F.adaptive_avg_pool2d):\n",
        "        super().__init__()\n",
        "        self.pool_type = pool_type\n",
        "        self.backbone = EfficientNet.from_pretrained(model_name)\n",
        "        in_features = getattr(self.backbone,'_fc').in_features\n",
        "        self.classifier = nn.Linear(in_features,1)\n",
        "    def forward(self,x):\n",
        "        features = self.pool_type(self.backbone.extract_features(x),1)\n",
        "        features = features.view(x.size(0),-1)\n",
        "        return self.classifier(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22Ci9i550x7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch_ranger --quiet\n",
        "from pytorch_ranger import Ranger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Atp8Ghw2Wtsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.optim.SGD()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myzwr5MfHUI3",
        "colab_type": "text"
      },
      "source": [
        "# Helper functions \n",
        "- Split data to train and validation split\n",
        "- Get model, choose different optimizer, freeze backbone, different learning rates/weight decay.\n",
        "- The training method by default uses cosine annealing for scheduling learning rate, you can experiment with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kV_krTrZHUI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_device():\n",
        "    return torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "def get_model(model_name='efficientnet-b3',lr=1e-3,wd=0.01,opt_fn=Ranger,device=None):\n",
        "    device = device if device else get_device()\n",
        "    model = MelanomaEfficientNet(model_name=model_name)\n",
        "    opt = opt_fn(model.parameters(),lr=lr,weight_decay=wd)\n",
        "    model = model.to(device)\n",
        "    return model, opt\n",
        "\n",
        "def training_step(xb,yb,model,loss_fn,opt,device,scheduler):\n",
        "    xb,yb = xb.to(device), yb.to(device)\n",
        "    out = model(xb)\n",
        "    opt.zero_grad()\n",
        "    loss = loss_fn(out,yb)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    scheduler.step()\n",
        "    return loss.item()\n",
        "    \n",
        "def validation_step(xb,yb,model,loss_fn,device):\n",
        "    xb,yb = xb.to(device), yb.to(device)\n",
        "    out = model(xb)\n",
        "    loss = loss_fn(out,yb)\n",
        "    out = torch.sigmoid(out)\n",
        "    return loss.item(),out\n",
        "\n",
        "def hold_step(xb,yb,model,loss_fn,device):\n",
        "    xb,yb = xb.to(device), yb.to(device)\n",
        "    out = model(xb)\n",
        "    loss = loss_fn(out,yb)\n",
        "    out = torch.sigmoid(out)\n",
        "    return loss.item(),out\n",
        "\n",
        "def get_data(train_df,valid_df,train_tfms,test_tfms,bs):\n",
        "    train_ds = MelanomaDataset(df=train_df,im_path=path/'train',transforms=train_tfms)\n",
        "    valid_ds = MelanomaDataset(df=valid_df,im_path=path/'train',transforms=test_tfms)\n",
        "    hold_ds =  MelanomaDataset(df=hold_df,im_path=path/'train',transforms=test_tfms)\n",
        "    train_dl = DataLoader(dataset=train_ds,batch_size=bs,shuffle=True,num_workers=4)\n",
        "    valid_dl = DataLoader(dataset=valid_ds,batch_size=bs*2,shuffle=False,num_workers=4)\n",
        "    hold_dl = DataLoader(dataset=hold_ds,batch_size=bs*2,shuffle=False,num_workers=4)\n",
        "    return train_dl,valid_dl,hold_dl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plW5_Hy-9Adi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss_update(epoch, epochs, mb, train_loss, valid_loss):\n",
        "    \"\"\" dynamically print the loss plot during the training/validation loop.\n",
        "        expects epoch to start from 1.\n",
        "    \"\"\"\n",
        "    x = range(1, epoch+1)\n",
        "    y = np.concatenate((train_loss, valid_loss))\n",
        "    graphs = [[x,train_loss], [x,valid_loss]]\n",
        "    x_margin = 0.2\n",
        "    y_margin = 0.05\n",
        "    x_bounds = [1-x_margin, epochs+x_margin]\n",
        "    y_bounds = [np.min(y)-y_margin, np.max(y)+y_margin]\n",
        "\n",
        "    mb.update_graph(graphs, x_bounds, y_bounds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqFO_TJAZaEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checkpoint=torch.load('/content/drive/My Drive/last_epochfold4.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MMsxJm0vHUI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs,model,train_dl,valid_dl,opt,device=None,loss_fn=F.binary_cross_entropy_with_logits):\n",
        "    device = device if device else get_device()\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, len(train_dl)*epochs)\n",
        "    #checkpoint=torch.load('/content/drive/My Drive/effnet_b4_Ranger_fold1_last_epoch-further3.pth')\n",
        "    #scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "    #del checkpoint\n",
        "    val_rocs = [] \n",
        "    #hold_rocs=[]\n",
        "    best_roc=0\n",
        "    mb = master_bar(range(9,epochs+9))\n",
        "    for epoch in mb:    \n",
        "        trn_loss,val_loss,hold_loss = 0.0,0.0,0.0\n",
        "        val_preds = np.zeros((len(valid_dl.dataset),1))\n",
        "        val_targs = np.zeros((len(valid_dl.dataset),1))\n",
        "        #hold_preds = np.zeros((len(valid_dl.dataset),1))\n",
        "        #hold_targs = np.zeros((len(valid_dl.dataset),1))\n",
        "        #Training\n",
        "        model.train()\n",
        "      \n",
        "        #For every batch \n",
        "        for xb,yb in progress_bar(train_dl,parent=mb):\n",
        "            trn_loss += training_step(xb,yb,model,loss_fn,opt,device,scheduler)\n",
        "            writer.add_scalar(\"Loss/train\", trn_loss, epoch)\n",
        "        trn_loss /= mb.child.total\n",
        "\n",
        "        #Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i,(xb,yb) in enumerate(progress_bar(valid_dl,parent=mb)):\n",
        "                loss,out = validation_step(xb,yb,model,loss_fn,device)\n",
        "                val_loss += loss\n",
        "                writer.add_scalar(\"Loss/val\",val_loss, epoch)\n",
        "                bs = xb.shape[0]\n",
        "                val_preds[i*bs:i*bs+bs] = out.cpu().numpy()\n",
        "                val_targs[i*bs:i*bs+bs] = yb.cpu().numpy()\n",
        "        val_loss /= mb.child.total\n",
        "        val_roc = roc_auc_score(val_targs.reshape(-1),val_preds.reshape(-1))\n",
        "        val_rocs.append(val_roc)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i,(xb,yb) in enumerate(progress_bar(hold_dl,parent=mb)):\n",
        "                loss,out = hold_step(xb,yb,model,loss_fn,device)\n",
        "                hold_loss += loss\n",
        "                writer.add_scalar(\"Loss/hold\",hold_loss, epoch)\n",
        "                bs = xb.shape[0]\n",
        "                hold_preds[i*bs:i*bs+bs] = out.cpu().numpy()\n",
        "                hold_targs[i*bs:i*bs+bs] = yb.cpu().numpy()\n",
        "        hold_loss /= mb.child.total\n",
        "        hold_roc = roc_auc_score(hold_targs.reshape(-1),hold_preds.reshape(-1))\n",
        "        hold_rocs.append(hold_roc)\n",
        "        if val_roc>best_roc:\n",
        "          best_roc=val_roc\n",
        "          torch.save(model.state_dict(),f'/content/drive/My Drive/effb4_best_auc_Ranger_fold4-further3.pth')\n",
        "        torch.save({'model_state_dict':model.state_dict(),'scheduler_state_dict':scheduler.state_dict(),'optimizer_state_dict':opt.state_dict(),'val_loss':val_loss,'val_roc':val_roc},f'/content/drive/My Drive/effnet_b4_Ranger_fold4_last_epoch-further3.pth')\n",
        "        print(f'Epoch: {epoch},Train_loss: {trn_loss:.5f},Val_roc:{val_roc:.4f},Val_loss:{val_loss:.5f},lr:{get_lr(opt)}')\n",
        "        with open('/content/drive/My Drive/effnetb4/log_fold4.txt','a+') as f:\n",
        "          f.writelines(f'Epoch: {epoch},Train_loss: {trn_loss:.5f},Val_roc:{val_roc:.4f},Hold_ROC:{hold_roc:.4f},Val_loss:{val_loss:.5f},lr:{get_lr(opt)}\\n')\n",
        "    writer.flush()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_kg_hide-output": true,
        "id": "IIiqjrDdHUI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df,valid_df,hold_df= get_train_val_split(tr_concat)\n",
        "train_tfms,test_tfms = get_augmentations(p=0.6)\n",
        "train_dl,valid_dl,hold_dl = get_data(train_df,valid_df,train_tfms,test_tfms,bs)\n",
        "model,opt = get_model(model_name='efficientnet-b4',lr=2e-5,wd=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkzm4W2_9hJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#del checkpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzn_tbytUT7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSYHVJFUHUJB",
        "colab_type": "text"
      },
      "source": [
        "I trained the model on my local machine. You can uncomment below code to start training here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1SRD7oLeHUJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model,val_rocs = fit(35,model,train_dl,valid_dl,opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOBR4r59-zyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26Dn6xpuHUJD",
        "colab_type": "text"
      },
      "source": [
        "# Generate test predictions\n",
        "\n",
        "- By default we use the same data augmentation techniques that we applied during training. \n",
        "- Tweak the TTA parameter in `get_preds()` to increase the number of times TTA is applied.\n",
        "- If you do not want TTA, change `transforms` to `test_transforms`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7XUvqBTfHUJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y7034urGHUJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagenet_stats = {'mean':[0.485, 0.456, 0.406], 'std':[0.229, 0.224, 0.225]}\n",
        "test_tfms1 = A.Compose([ \n",
        "    A.Resize(512,512),               \n",
        "    ToTensor(normalize=imagenet_stats)\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_kg_hide-output": true,
        "id": "0IdK3btvHUJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test_df = pd.read_csv(path/'test.csv')\n",
        "\n",
        "model, opt = get_model(model_name='efficientnet-b4',lr=1e-4,wd=1e-4)\n",
        "model.load_state_dict(torch.load(f'/content/drive/My driveeffb4_best_auc_Ranger_fold4.pth',map_location=device))\n",
        "\n",
        "#Testing with lighter augmentation\n",
        "test_ds = MelanomaDataset(df=test_df,im_path='test',transforms=test_tfms1,is_test=True)\n",
        "test_dl = DataLoader(dataset=test_ds,batch_size=32,shuffle=False,num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQBGscKCmZNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_ds = MelanomaDataset(df=test_df,im_path='test',transforms=test_tfms1,is_test=True)\n",
        "test_dl = DataLoader(dataset=test_ds,batch_size=32,shuffle=False,num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shazdBjDjgUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_ds = MelanomaDataset(df=valid_df,im_path='train',transforms=test_tfms1,is_test=False)\n",
        "valid_dl = DataLoader(dataset=valid_ds,batch_size=32,shuffle=False,num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a41XP6JYUiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.train(False)\n",
        "valid_preds2=[]\n",
        "tk = tqdm(valid_dl, total=len(valid_dl), position=0, leave=True)\n",
        "for i,(inputs,labels) in enumerate(tk):\n",
        "  #labels=labels.type(torch.float32)\n",
        "  inputs=inputs.to(device)\n",
        "  labels=labels.to(device)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "        outputs=model(inputs)\n",
        "        pred = torch.sigmoid(outputs)\n",
        "  valid_preds2.extend(pred.detach().cpu().numpy())\n",
        "  del outputs\n",
        "  del pred\n",
        "  gc.collect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7GV_ZDhlfIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roc_auc_score(valid_df.target,valid_preds2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXDcytCan3CN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.train(False)\n",
        "valid_preds2=[]\n",
        "tk = tqdm(test_dl, total=len(test_dl), position=0, leave=True)\n",
        "for i,(inputs) in enumerate(tk):\n",
        "  #labels=labels.type(torch.float32)\n",
        "  inputs=inputs.to(device)\n",
        "  #labels=labels.to(device)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "        outputs=model(inputs)\n",
        "        pred = torch.sigmoid(outputs)\n",
        "  valid_preds2.extend(pred.detach().cpu().numpy())\n",
        "  del outputs\n",
        "  del pred\n",
        "  gc.collect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_kg_hide-output": true,
        "id": "Hie1IUICHUJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing for Test Time Augmentation\n",
        "def get_preds(model,device=None,tta=3):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    preds = np.zeros(len(test_ds))\n",
        "    for tta_id in range(tta):\n",
        "        test_preds = []\n",
        "        with torch.no_grad():\n",
        "            for xb in test_dl:\n",
        "                xb = xb.to(device)\n",
        "                out = model(xb)\n",
        "                out = torch.sigmoid(out)\n",
        "                test_preds.extend(out.cpu().numpy())\n",
        "            preds += np.array(test_preds).reshape(-1)\n",
        "        print(f'TTA {tta_id}')\n",
        "    preds /= tta\n",
        "    return preds\n",
        "\n",
        "#Changing tta to 25 from 10\n",
        "preds = get_preds(model,tta=1)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "n_gxllyHHUJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subm = pd.read_csv('/content/jpeg-melanoma-512x512/sample_submission.csv')\n",
        "subm.target = pd.DataFrame(valid_preds2)\n",
        "subm.to_csv('submission_b4_384-fold4-final.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBjrsC59ntTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subm"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}